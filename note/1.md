# p1
# p2
# p3
# p4
# p5

- ÈìæÂºèËøûÊé•

```
from langchain_core.prompts import PromptTemplate
prompt_template = PromptTemplate("tell me a joke about {topic}")
prompt = prompt_template.format(topic="cats")
print(prompt)  # Output: tell me a joke about cats
```

```
# Êñá‰ª∂Âä†ËΩΩËµ∑
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import NoionDirectoryLoader
from langchain_community.document_loaders import UnstructuredFileLoader
notion_loader = NoionDirectoryLoader(
    path="notion",
    glob="**/*.md",
    recursive=True,
    show_progress=True,
    metadata={"source": "notion"}
)
pdf_loader = PyPDFLoader(
    path="pdf",
    glob="**/*.pdf",
    recursive=True,
    show_progress=True,
    metadata={"source": "pdf"}
)
pdf_docs = pdf_loader.load()
email_loader = UnstructedEmailLoader(
    path="email",
    glob="**/*.eml",
    recursive=True,
    show_progress=True, 
    metadata={"source": "email"}
)
email_docs = email_loader.load()
notion_docs = notion_loader.load()
```
# p6

```
pipenv install langchain-openai
```

```
pipenv install langchainhub
```

```
pipenv install black
```
# p7

```
pipenv install langchain-openai
```

```
pipenv install langchain-community
```

```
pipenv install langchainhub
```

# p8

# p9

```
PromptTemplate

human message

ai message

summary_yemplate="""given the information{summary}"""

summary_prompt_tenplate = PromptTempalte(input_variables="information",template=summary_template__'

llm = ChatOepnAi(temperature =0,model_name="gpt-3.5-trubo")

res = chain.invoke(input={"information‚ÄúÔºöinformation})
```

langchain_tracing_v2=trueÔºåyou must have a valid langsmith api key set in langchian_api_key.

<img width="929" height="299" alt="image" src="https://github.com/user-attachments/assets/7c37fcae-a75e-49ff-960c-e212a55b04eb" />

ÈÅøÂÖçÊé•Âèó403ÁöÑÈîôËØØ

# p10Êú¨Âú∞ÂåñÈÉ®ÁΩ≤

ollamaÊú¨Âú∞ÂåñÈÉ®ÁΩ≤Ôºå

ollama run llama3


llm = ChatOllama(model="llama3")

contentÂ±ûÊÄßÔºåËÑ∏ÊòØË∞ÉÁî®ÁöÑÊú¨Ë∫´ÁöÑÔºå

outputparsers

ËΩ¨Êç¢Êàê‰∏∫‰∏•Ë∞®ÁöÑÂØπË±°ÔºåÂ≠óÁ¨¶‰∏≤ËæìÂá∫Ëß£ÊûêÂô®

chain=summary_prompt_template | llm |StrOutputParser

summary_prompt_template = PromptTemplate(
input_variable=["information"],template=summary_template
)


# p11
angchain

0.3.3

pipenv install langchain


# p13
ÈÄöËøáËæìÂÖ•ÂßìÂêçÔºåÊêúÁ¥¢Ëøô‰∏™ÂêçÂ≠óÁöÑÊé®ÁâπË¥¶Âè∑ÂíåÈ¢ÜËã±Ë¥¶Âè∑

```
from typing import Tuple
from agents.linkedin_lookup_agent import lookup as linkedin_lookup_agent
from agents.twitter_lookup_agent import lookup as twitter_lookup_agent
from chains.custom_chains import (
    get_summary_chain,
    get_interests_chain,
    get_ice_breaker_chain,
)
from third_parties.linkedin import scrape_linkedin_profile
from third_parties.twitter import scrape_user_tweets, scrape_user_tweets_mock
from output_parsers import (
    Summary,
    IceBreaker,
    TopicOfInterest,
)


def ice_break_with(
    name: str,
) -> Tuple[Summary, TopicOfInterest, IceBreaker, str]:
    linkedin_url = linkedin_lookup_agent(name=name)
    linkedin_data = scrape_linkedin_profile(linkedin_profile_url=linkedin_url)

    twitter_username = twitter_lookup_agent(name=name)
    tweets = scrape_user_tweets_mock(username=twitter_username)

    summary_chain = get_summary_chain()
    summary_and_facts: Summary = summary_chain.invoke(
        input={"information": linkedin_data, "twitter_posts": tweets},
    )

    interests_chain = get_interests_chain()
    interests: TopicOfInterest = interests_chain.invoke(
        input={"information": linkedin_data, "twitter_posts": tweets}
    )

    ice_breaker_chain = get_ice_breaker_chain()
    ice_breakers: IceBreaker = ice_breaker_chain.invoke(
        input={"information": linkedin_data, "twitter_posts": tweets}
    )

    return (
        summary_and_facts,
        interests,
        ice_breakers,
        linkedin_data.get("photoUrl"),
    )


if __name__ == "__main__":
    pass

```

# p14

scraping.io 20ÁæéÂàÜÂÖçË¥π

Scraping.IO


print


requests

pprint.pprint(requests.get("https://

```
import os
import requests
from dotenv import load_dotenv

load_dotenv()


def scrape_linkedin_profile(linkedin_profile_url: str, mock: bool = False):
    """scrape information from LinkedIn profiles,
    Manually scrape the information from the LinkedIn profile"""

    if mock:
        linkedin_profile_url = "https://gist.githubusercontent.com/emarco177/859ec7d786b45d8e3e3f688c6c9139d8/raw/32f3c85b9513994c572613f2c8b376b633bfc43f/eden-marco-scrapin.json"
        response = requests.get(
            linkedin_profile_url,
            timeout=10,
        )
    else:
        api_endpoint = "https://api.scrapin.io/enrichment/profile"
        params = {
            "apikey": os.environ["SCRAPIN_API_KEY"],
            "linkedInUrl": linkedin_profile_url,
        }
        response = requests.get(
            api_endpoint,
            params=params,
            timeout=10,
        )

    data = response.json().get("person")
    data = {
        k: v
        for k, v in data.items()
        if v not in ([], "", "", None) and k not in ["certifications"]
    }

    return data


if __name__ == "__main__":
    print(
        scrape_linkedin_profile(
            linkedin_profile_url="https://www.linkedin.com/in/eden-marco/"
        ),
    )

```

```
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import Tool
from langchain_openai import ChatOpenAI
from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor

from dotenv import load_dotenv
from tools.tools import get_profile_url_tavily

load_dotenv()


def lookup(name: str) -> str:
    llm = ChatOpenAI(temperature=0, model_name="gpt-4o-mini")
    template = """
       given the name {name_of_person} I want you to find a link to their Twitter/ X profile page, and extract from it their username
       In Your Final answer only the person's username
       which is extracted from: https://x.com/USERNAME"""
    tools_for_agent_twitter = [
        Tool(
            name="Crawl Google 4 Twitter profile page",
            func=get_profile_url_tavily,
            description="useful for when you need get the Twitter Page URL",
        ),
    ]

    prompt_template = PromptTemplate(
        input_variables=["name_of_person"], template=template
    )

    react_prompt = hub.pull("hwchase17/react")
    agent = create_react_agent(
        llm=llm, tools=tools_for_agent_twitter, prompt=react_prompt
    )
    agent_executor = AgentExecutor(
        agent=agent, tools=tools_for_agent_twitter, verbose=True
    )

    result = agent_executor.invoke(
        input={"input": prompt_template.format_prompt(name_of_person=name)}
    )

    twitter_username = result["output"]

    return twitter_username

```

# 15

# 16
# 17

<img width="789" height="425" alt="image" src="https://github.com/user-attachments/assets/78fd4983-839e-4dc9-8b38-0cbf9142694b" />


```
def get_profile_url_tavily(name:str):
    search = TavilySearchResults()
    res = search.run(f"{name}")


def lookup(name:str)->str:
    llm = ChatOpenAI(
        temperature=0,
        model_name="gpt-3.5-turbo",
    )
    template = """
    You are a helpful assistant that provides information about Python modules.
    Given a module name, return a brief description of what the module does.
    Module name: {name}
    """
    prompt = PromptTemplate(
        input_variables=["name"],
        template=template,
    )
    tools_for_agent = [
        Tool(
            name="lookup",
            func=llm,
            description="Use this tool to look up information about Python modules."
        )
    ]
    react_prompt = hub.pull("hwchase17/react")
    agent = create_react_agent(
        llm=llm,
        tools=tools_for_agent,
        prompt=react_prompt,
    )
    agent_executor = agent_executor(
        agent=agent,
        tools=tools_for_agent,
        verbose=True,
    )
    result = agent_executor.invoke(
        input={"input":prompt_template.format_prompt(name_of-_person=name)}
    )
    linked_profile_url = result["output"]
    return linked_profile_url
```
# üèÉp20





